{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b92fd5-c459-4894-b27c-961e44698a1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d22c28-d6b6-405b-9de7-08040683a715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split in module pyspark.sql.functions:\n\nsplit(str: 'ColumnOrName', pattern: str, limit: int = -1) -> pyspark.sql.column.Column\n    Splits str around matches of the given pattern.\n    \n    .. versionadded:: 1.5.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    str : :class:`~pyspark.sql.Column` or str\n        a string expression to split\n    pattern : str\n        a string representing a regular expression. The regex string should be\n        a Java regular expression.\n    limit : int, optional\n        an integer which controls the number of times `pattern` is applied.\n    \n        * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n                         resulting array's last entry will contain all input beyond the last\n                         matched pattern.\n        * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n                          array can be of any size.\n    \n        .. versionchanged:: 3.0\n           `split` now takes an optional `limit` field. If not provided, default limit value is -1.\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        array of separated strings.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n    >>> df.select(split(df.s, '[ABC]', 2).alias('s')).collect()\n    [Row(s=['one', 'twoBthreeC'])]\n    >>> df.select(split(df.s, '[ABC]', -1).alias('s')).collect()\n    [Row(s=['one', 'two', 'three', ''])]\n\n"
     ]
    }
   ],
   "source": [
    "help(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b631c235-d76c-4281-8519-d6ec2c08ff78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function explode in module pyspark.sql.functions:\n\nexplode(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Returns a new row for each element in the given array or map.\n    Uses the default column name `col` for elements in the array and\n    `key` and `value` for elements in the map unless specified otherwise.\n    \n    .. versionadded:: 1.4.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    col : :class:`~pyspark.sql.Column` or str\n        target column to work on.\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        one row per array item or map key value.\n    \n    See Also\n    --------\n    :meth:`pyspark.functions.posexplode`\n    :meth:`pyspark.functions.explode_outer`\n    :meth:`pyspark.functions.posexplode_outer`\n    \n    Examples\n    --------\n    >>> from pyspark.sql import Row\n    >>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n    >>> eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()\n    [Row(anInt=1), Row(anInt=2), Row(anInt=3)]\n    \n    >>> eDF.select(explode(eDF.mapfield).alias(\"key\", \"value\")).show()\n    +---+-----+\n    |key|value|\n    +---+-----+\n    |  a|    b|\n    +---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "help(explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd2514c3-022f-444a-b0ea-caa7f613e8af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "l = [('X',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51ba22b-f0a9-4c0b-b08a-850ee7fd994b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l,\"dummy string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a00db8-83ac-4fb3-bff9-352c8dc4c4bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n|dummy|\n+-----+\n|    X|\n+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78b6e88e-876a-480c-a8cf-fbfd7bc2a84b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n|word                          |\n+------------------------------+\n|[Hello, world,, how, are, you]|\n+------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(split(lit(\"Hello world, how are you\"),\" \").alias(\"word\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ace0020-3c9c-410e-96f0-96c92f0071b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|   col|\n+------+\n| Hello|\n|world,|\n|   how|\n|   are|\n|   you|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(explode(split(lit(\"Hello world, how are you\"),\" \").alias('word'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03a92fc5-7319-43a0-bb15-e8b4f4408f7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    (1, \"Scott\", \"Tiger\", 1000.0, \"united states\", \"+1 123 456 7890,+1 234 567 8901\", \"123 45 6789\"),\n",
    "    (2, \"Henry\", \"Ford\", 1250.0, \"india\", \"+91 234 567 8901\", \"456 78 9123\"),\n",
    "    (3, \"Nick\", \"Junior\", 750.0, \"united kingdom\", \"+44 111 111 111,+44 222 222 2222\", \"222 33 4444\"),\n",
    "    (4, \"Bill\", \"Gomes\", 1500.0, \"australia\", \"+61 987 654 3210,+61 876 543 2109\", \"789 12 6118\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c508c0-eb9b-4298-9827-f4e2d307e8cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "empdf = spark.createDataFrame(employees, schema = \"\"\"employee_id INT, first_name STRING,\n",
    "                              last_name STRING, salary FLOAT, nationality STRING,\n",
    "                              phone_number STRING, ssn STRING                              \n",
    "                               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7e942d-6977-4d14-9642-548f89c4672d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+---------------------------------+-----------+\n|employee_id|first_name|last_name|salary|nationality   |phone_number                     |ssn        |\n+-----------+----------+---------+------+--------------+---------------------------------+-----------+\n|1          |Scott     |Tiger    |1000.0|united states |+1 123 456 7890,+1 234 567 8901  |123 45 6789|\n|2          |Henry     |Ford     |1250.0|india         |+91 234 567 8901                 |456 78 9123|\n|3          |Nick      |Junior   |750.0 |united kingdom|+44 111 111 111,+44 222 222 2222 |222 33 4444|\n|4          |Bill      |Gomes    |1500.0|australia     |+61 987 654 3210,+61 876 543 2109|789 12 6118|\n+-----------+----------+---------+------+--------------+---------------------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "empdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6fb71c-5b4f-400f-8002-717cefd131d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n|employee_id|phone_number                     |\n+-----------+---------------------------------+\n|1          |+1 123 456 7890,+1 234 567 8901  |\n|2          |+91 234 567 8901                 |\n|3          |+44 111 111 111,+44 222 222 2222 |\n|4          |+61 987 654 3210,+61 876 543 2109|\n+-----------+---------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "empdf.select('employee_id','phone_number').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66bb7c44-3ff8-4841-bd07-b313a75aa42e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+-----------+----------------+\n|employee_id|phone_number                     |ssn        |phone_numbers   |\n+-----------+---------------------------------+-----------+----------------+\n|1          |+1 123 456 7890,+1 234 567 8901  |123 45 6789|+1 123 456 7890 |\n|1          |+1 123 456 7890,+1 234 567 8901  |123 45 6789|+1 234 567 8901 |\n|2          |+91 234 567 8901                 |456 78 9123|+91 234 567 8901|\n|3          |+44 111 111 111,+44 222 222 2222 |222 33 4444|+44 111 111 111 |\n|3          |+44 111 111 111,+44 222 222 2222 |222 33 4444|+44 222 222 2222|\n|4          |+61 987 654 3210,+61 876 543 2109|789 12 6118|+61 987 654 3210|\n|4          |+61 987 654 3210,+61 876 543 2109|789 12 6118|+61 876 543 2109|\n+-----------+---------------------------------+-----------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "empdf. \\\n",
    "    select('employee_id','phone_number','ssn'). \\\n",
    "    withColumn('phone_numbers', explode(split('phone_number',\",\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6916288f-e6f4-46e1-ba15-e543377a2871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----------+----------------+---------+-----------+---------+\n|employee_id|        phone_number|        ssn|   phone_numbers|area_code|phone_last4|ssn_last4|\n+-----------+--------------------+-----------+----------------+---------+-----------+---------+\n|          1|+1 123 456 7890,+...|123 45 6789| +1 123 456 7890|      123|       7890|     6789|\n|          1|+1 123 456 7890,+...|123 45 6789| +1 234 567 8901|      234|       8901|     6789|\n|          2|    +91 234 567 8901|456 78 9123|+91 234 567 8901|      234|       8901|     9123|\n|          3|+44 111 111 111,+...|222 33 4444| +44 111 111 111|      111|        111|     4444|\n|          3|+44 111 111 111,+...|222 33 4444|+44 222 222 2222|      222|       2222|     4444|\n|          4|+61 987 654 3210,...|789 12 6118|+61 987 654 3210|      987|       3210|     6118|\n|          4|+61 987 654 3210,...|789 12 6118|+61 876 543 2109|      876|       2109|     6118|\n+-----------+--------------------+-----------+----------------+---------+-----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "empdf.\\\n",
    "    select('employee_id','phone_number','ssn'). \\\n",
    "    withColumn('phone_numbers', explode(split('phone_number',\",\"))). \\\n",
    "    withColumn('area_code', split('phone_numbers',\" \")[1].cast('int')). \\\n",
    "    withColumn('phone_last4', split('phone_numbers',\" \")[3].cast('int')). \\\n",
    "    withColumn('ssn_last4', split('ssn',\" \")[2].cast('int')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77cfd8cc-80ee-4ebc-8017-fe068c17a275",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09 - Extracting strings using split from Spark Data Frame Columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
