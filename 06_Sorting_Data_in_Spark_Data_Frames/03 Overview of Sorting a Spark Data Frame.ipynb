{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43e09c33-faca-47c6-89ef-e66ba670e762",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n|id |first_name|last_name   |email               |phone_numbers                   |courses|is_customer|amount_paid|customer_from|last_updated_ts    |\n+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n|1  |Corrie    |Van den Oord|cvandenoor@etsy.com |{+91 8645879087, +91 9878673289}|[1, 2] |true       |1000.55    |2021-01-15   |2021-02-10 01:15:00|\n|2  |John      |Cena        |john@cena.com       |{+91 9886879087, +91 9134673289}|[1]    |true       |900.0      |2022-05-15   |2024-03-15 01:16:00|\n|3  |James     |Bond        |james@bond.com      |{+91 3245879087, +91 9854673289}|[2, 3] |false      |750.6      |2023-01-12   |2018-05-05 05:17:02|\n|4  |Robert    |Dowrey      |robert@dowrey.com   |NULL                            |[2]    |true       |500.5      |NULL         |2019-04-03 08:14:08|\n|5  |Chris     |Hemmsworth  |chris@hemmsworth.com|{+91 9085879087, }              |[3, 4] |false      |NaN        |NULL         |2019-04-03 08:14:08|\n+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "%run \"/Users/surajthallapalli@outlook.com/06 Sorting Data in Spark Data Frames/02 - Creating Spark Data Frame for Sorting the Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef91d908-6878-4f50-88d3-e1e280d3e969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n|id |first_name|last_name   |email               |phone_numbers                   |courses|is_customer|amount_paid|customer_from|last_updated_ts    |\n+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n|1  |Corrie    |Van den Oord|cvandenoor@etsy.com |{+91 8645879087, +91 9878673289}|[1, 2] |true       |1000.55    |2021-01-15   |2021-02-10 01:15:00|\n|2  |John      |Cena        |john@cena.com       |{+91 9886879087, +91 9134673289}|[1]    |true       |900.0      |2022-05-15   |2024-03-15 01:16:00|\n|3  |James     |Bond        |james@bond.com      |{+91 3245879087, +91 9854673289}|[2, 3] |false      |750.6      |2023-01-12   |2018-05-05 05:17:02|\n|4  |Robert    |Dowrey      |robert@dowrey.com   |NULL                            |[2]    |true       |500.5      |NULL         |2019-04-03 08:14:08|\n|5  |Chris     |Hemmsworth  |chris@hemmsworth.com|{+91 9085879087, }              |[3, 4] |false      |NaN        |NULL         |2019-04-03 08:14:08|\n+---+----------+------------+--------------------+--------------------------------+-------+-----------+-----------+-------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "userdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6ef731-c5fe-4493-99d6-db8634b8d18c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort in module pyspark.sql.dataframe:\n\nsort(*cols: Union[str, pyspark.sql.column.Column, List[Union[str, pyspark.sql.column.Column]]], **kwargs: Any) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` sorted by the specified column(s).\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    cols : str, list, or :class:`Column`, optional\n         list of :class:`Column` or column names to sort by.\n    \n    Other Parameters\n    ----------------\n    ascending : bool or list, optional, default True\n        boolean or list of boolean.\n        Sort ascending vs. descending. Specify list for multiple sort orders.\n        If a list is specified, the length of the list must equal the length of the `cols`.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        Sorted DataFrame.\n    \n    Examples\n    --------\n    >>> from pyspark.sql.functions import desc, asc\n    >>> df = spark.createDataFrame([\n    ...     (2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    \n    Sort the DataFrame in ascending order.\n    \n    >>> df.sort(asc(\"age\")).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  2|Alice|\n    |  5|  Bob|\n    +---+-----+\n    \n    Sort the DataFrame in descending order.\n    \n    >>> df.sort(df.age.desc()).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    >>> df.orderBy(df.age.desc()).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    >>> df.sort(\"age\", ascending=False).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    \n    Specify multiple columns\n    \n    >>> df = spark.createDataFrame([\n    ...     (2, \"Alice\"), (2, \"Bob\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    >>> df.orderBy(desc(\"age\"), \"name\").show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    |  2|  Bob|\n    +---+-----+\n    \n    Specify multiple columns for sorting order at `ascending`.\n    \n    >>> df.orderBy([\"age\", \"name\"], ascending=[False, False]).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|  Bob|\n    |  2|Alice|\n    +---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "help(userdf.sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b9846ea-72f5-47dc-8ffd-45d5d97abab1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort in module pyspark.sql.dataframe:\n\nsort(*cols: Union[str, pyspark.sql.column.Column, List[Union[str, pyspark.sql.column.Column]]], **kwargs: Any) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` sorted by the specified column(s).\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    cols : str, list, or :class:`Column`, optional\n         list of :class:`Column` or column names to sort by.\n    \n    Other Parameters\n    ----------------\n    ascending : bool or list, optional, default True\n        boolean or list of boolean.\n        Sort ascending vs. descending. Specify list for multiple sort orders.\n        If a list is specified, the length of the list must equal the length of the `cols`.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        Sorted DataFrame.\n    \n    Examples\n    --------\n    >>> from pyspark.sql.functions import desc, asc\n    >>> df = spark.createDataFrame([\n    ...     (2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    \n    Sort the DataFrame in ascending order.\n    \n    >>> df.sort(asc(\"age\")).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  2|Alice|\n    |  5|  Bob|\n    +---+-----+\n    \n    Sort the DataFrame in descending order.\n    \n    >>> df.sort(df.age.desc()).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    >>> df.orderBy(df.age.desc()).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    >>> df.sort(\"age\", ascending=False).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    +---+-----+\n    \n    Specify multiple columns\n    \n    >>> df = spark.createDataFrame([\n    ...     (2, \"Alice\"), (2, \"Bob\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    >>> df.orderBy(desc(\"age\"), \"name\").show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|Alice|\n    |  2|  Bob|\n    +---+-----+\n    \n    Specify multiple columns for sorting order at `ascending`.\n    \n    >>> df.orderBy([\"age\", \"name\"], ascending=[False, False]).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  5|  Bob|\n    |  2|  Bob|\n    |  2|Alice|\n    +---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "help(userdf.orderBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01f04cf1-0785-496d-b150-26c65213bd1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03 Overview of Sorting a Spark Data Frame",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
