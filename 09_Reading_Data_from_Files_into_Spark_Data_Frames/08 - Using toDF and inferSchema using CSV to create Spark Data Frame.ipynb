{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f246eac2-1166-4472-9d1a-5057250ff96d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = ['order_id', 'order_date', 'order_customer_id', 'order_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2da5d86-4fd5-4a9c-bf6e-bd93024b321a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[order_id: int, order_date: timestamp, order_customer_id: int, order_status: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.option('inferSchema', True).csv('/public/retail_db/orders').toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e91619b6-d59d-46ed-9c20-ba223ef861e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n|order_id|         order_date|order_customer_id|   order_status|\n+--------+-------------------+-----------------+---------------+\n|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n+--------+-------------------+-----------------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('inferSchema', True).csv('/public/retail_db/orders').toDF(*columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d1ff32-43d3-4623-a1e6-036ebb63b348",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[order_id: int, order_date: timestamp, order_customer_id: int, order_status: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv('/public/retail_db/orders', inferSchema=True).toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d32dd4d-7a24-4842-83bb-17faddf020ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n|order_id|         order_date|order_customer_id|   order_status|\n+--------+-------------------+-----------------+---------------+\n|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n+--------+-------------------+-----------------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv('/public/retail_db/orders', inferSchema=True).toDF(*columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0466c850-6b21-4618-9cc2-336d8308e58f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08 - Using toDF and inferSchema using CSV to create Spark Data Frame",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
