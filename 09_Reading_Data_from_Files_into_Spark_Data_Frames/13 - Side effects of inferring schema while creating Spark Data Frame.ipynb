{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d54b9b8-9d40-466e-b1a1-5eb2b09b657a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- If InferSchema is used entire data need to be read to inder the schema accurately while creating Data Frame\n",
    "- If the data size is too big then additional time will be spent to infer the schema\n",
    "- When we explicitly specify the schema, data will not be read while creating the Data Frame\n",
    "- As we have seen we should be able to explicitly specify the schema using string or StructType\n",
    "- Inferring Schema will come handy to quickly understand the structure of the data as part of POCs\n",
    "- Schema will be inferred by default for files of type JSON, Parquet and ORC. Column names and data types will be inferred using metadata that will be associated with these types of files\n",
    "- Inferring the schema on CSV files will create data frames with system generated column names. Also the data type of all columns will be string. If inferSchema is used then the data frame will determine the data  \n",
    "  types. If the files contains header, then column names can be inherited using it. If not, we need to explicitly pass the columns using toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cbb14e6-1625-47b8-8cd3-3497f26be7fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "13 - Side effects of inferring schema while creating Spark Data Frame",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
