{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb131ce8-1a76-4768-ac83-c9a7bab219f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders = spark.read.json('/public/retail_db_json/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f806286a-8653-4990-a0f5-b27f66751f68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d366ba-19cc-43cc-bf2e-1ee28e9f943b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function count in module pyspark.sql.functions:\n\ncount(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Aggregate function: returns the number of items in a group.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    col : :class:`~pyspark.sql.Column` or str\n        target column to compute on.\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        column for computed results.\n    \n    Examples\n    --------\n    Count by all columns (start), and by a column that does not count ``None``.\n    \n    >>> df = spark.createDataFrame([(None,), (\"a\",), (\"b\",), (\"c\",)], schema=[\"alphabets\"])\n    >>> df.select(count(expr(\"*\")), count(df.alphabets)).show()\n    +--------+----------------+\n    |count(1)|count(alphabets)|\n    +--------+----------------+\n    |       4|               3|\n    +--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "help(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644e303c-8f95-4f66-a478-bf1c6d2992bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+\n|order_customer_id|          order_date|order_id|   order_status|\n+-----------------+--------------------+--------+---------------+\n|            11599|2013-07-25 00:00:...|       1|         CLOSED|\n|              256|2013-07-25 00:00:...|       2|PENDING_PAYMENT|\n|            12111|2013-07-25 00:00:...|       3|       COMPLETE|\n|             8827|2013-07-25 00:00:...|       4|         CLOSED|\n|            11318|2013-07-25 00:00:...|       5|       COMPLETE|\n|             7130|2013-07-25 00:00:...|       6|       COMPLETE|\n|             4530|2013-07-25 00:00:...|       7|       COMPLETE|\n|             2911|2013-07-25 00:00:...|       8|     PROCESSING|\n|             5657|2013-07-25 00:00:...|       9|PENDING_PAYMENT|\n|             5648|2013-07-25 00:00:...|      10|PENDING_PAYMENT|\n|              918|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|\n|             1837|2013-07-25 00:00:...|      12|         CLOSED|\n|             9149|2013-07-25 00:00:...|      13|PENDING_PAYMENT|\n|             9842|2013-07-25 00:00:...|      14|     PROCESSING|\n|             2568|2013-07-25 00:00:...|      15|       COMPLETE|\n|             7276|2013-07-25 00:00:...|      16|PENDING_PAYMENT|\n|             2667|2013-07-25 00:00:...|      17|       COMPLETE|\n|             1205|2013-07-25 00:00:...|      18|         CLOSED|\n|             9488|2013-07-25 00:00:...|      19|PENDING_PAYMENT|\n|             9198|2013-07-25 00:00:...|      20|     PROCESSING|\n+-----------------+--------------------+--------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa9012e-41dc-416a-98cf-d413e92e07c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n|   order_status|count(1)|\n+---------------+--------+\n|PENDING_PAYMENT|   15030|\n|       COMPLETE|   22899|\n|        ON_HOLD|    3798|\n| PAYMENT_REVIEW|     729|\n|     PROCESSING|    8275|\n|         CLOSED|    7556|\n|SUSPECTED_FRAUD|    1558|\n|        PENDING|    7610|\n|       CANCELED|    1428|\n+---------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "orders.groupBy('order_status').agg(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ded0c7d-9c88-4bd8-b947-3474889ecf14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03 - Common Spark aggregate functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
