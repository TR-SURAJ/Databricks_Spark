{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c691ebf-0e3f-4e7b-8983-522c865fccd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord| cvandenoor@etsy.com|{+91 8645879087, ...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|      John|        Cena|       john@cena.com|{+91 9886879087, ...| [3, 4]|       true|      900.0|   2022-05-15|2024-03-15 01:16:00|\n|  3|     James|        Bond|      james@bond.com|{+91 3245879087, ...|    [2]|      false|      750.6|   2023-01-12|2018-05-05 05:17:02|\n|  4|    Robert|      Dowrey|   robert@dowrey.com|                null|     []|       true|        NaN|         null|2019-04-03 08:14:08|\n|  5|     Chris|  Hemmsworth|chris@hemmsworth.com|{+91 9085879087, ...|     []|      false|        NaN|         null|2019-04-03 08:14:08|\n+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: [('id', 'bigint'),\n ('first_name', 'string'),\n ('last_name', 'string'),\n ('email', 'string'),\n ('phone_numbers', 'struct<mobile:string,home:string>'),\n ('courses', 'array<bigint>'),\n ('is_customer', 'boolean'),\n ('amount_paid', 'double'),\n ('customer_from', 'date'),\n ('last_updated_ts', 'timestamp')]"
     ]
    }
   ],
   "source": [
    "%run \"/Users/surajthallapalli@outlook.com/02 Selecting and Renaming Columns in Spark Dataframe/Creating Spark Dataframe 2023-07-11 20:32:19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb4c5eeb-2c63-4baf-b3ea-3148bf76fdf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: Column<'id'>"
     ]
    }
   ],
   "source": [
    "users_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c1c613-460a-4a1f-b9d5-30bba534632e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d5e8f16-e2cb-4390-9af4-b72481c22f7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: Column<'id'>"
     ]
    }
   ],
   "source": [
    "col('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a230eb6-065b-4d4e-8c98-2ba72bffdb6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: pyspark.sql.column.Column"
     ]
    }
   ],
   "source": [
    "type(users_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c8915a-96ba-47f5-a60d-fe3294e762d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|      John|        Cena|\n|  3|     James|        Bond|\n|  4|    Robert|      Dowrey|\n|  5|     Chris|  Hemmsworth|\n+---+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_df.select('id', col('first_name'), col('last_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2792d82-434e-479b-9fb3-5083c1a3539f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|      John|        Cena|\n|  3|     James|        Bond|\n|  4|    Robert|      Dowrey|\n|  5|     Chris|  Hemmsworth|\n+---+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_df.select(users_df['id'], users_df['first_name'],'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2dfd676-fa9f-4619-b06a-abce69026ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3694830399309608>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This does not work as there is no object by name u in this session\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m users_df\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mselect(\u001B[43mu\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m], col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'u' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3694830399309608>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This does not work as there is no object by name u in this session\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m users_df\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mselect(\u001B[43mu\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m], col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n\n\u001B[0;31mNameError\u001B[0m: name 'u' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'u' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This does not work as there is no object by name u in this session\n",
    "users_df.alias('u').select(u['id'], col('first_name'), 'last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "912cbbeb-6e2a-47e1-a79c-ea7a04030021",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|      John|        Cena|\n|  3|     James|        Bond|\n|  4|    Robert|      Dowrey|\n|  5|     Chris|  Hemmsworth|\n+---+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# This will work\n",
    "users_df.alias('u').select('u.id', 'u.first_name', col('last_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc1b2b9-2b16-4b67-b14f-e496fc22b2b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3694830399309610>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This does not work as selectExpr can only take column names or SQL style expressions on column names\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43musers_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselectExpr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfirst_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlast_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3063\u001B[0m, in \u001B[0;36mDataFrame.selectExpr\u001B[0;34m(self, *expr)\u001B[0m\n",
       "\u001B[1;32m   3061\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(expr) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(expr[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n",
       "\u001B[1;32m   3062\u001B[0m     expr \u001B[38;5;241m=\u001B[39m expr[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n",
       "\u001B[0;32m-> 3063\u001B[0m jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mselectExpr(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jseq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexpr\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m   3064\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2624\u001B[0m, in \u001B[0;36mDataFrame._jseq\u001B[0;34m(self, cols, converter)\u001B[0m\n",
       "\u001B[1;32m   2618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_jseq\u001B[39m(\n",
       "\u001B[1;32m   2619\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m   2620\u001B[0m     cols: Sequence,\n",
       "\u001B[1;32m   2621\u001B[0m     converter: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrimitiveType\u001B[39m\u001B[38;5;124m\"\u001B[39m, JavaObject]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m   2622\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JavaObject:\n",
       "\u001B[1;32m   2623\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 2624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n",
       "\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n",
       "\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Column is not iterable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3694830399309610>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This does not work as selectExpr can only take column names or SQL style expressions on column names\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43musers_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselectExpr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfirst_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlast_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3063\u001B[0m, in \u001B[0;36mDataFrame.selectExpr\u001B[0;34m(self, *expr)\u001B[0m\n\u001B[1;32m   3061\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(expr) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(expr[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m   3062\u001B[0m     expr \u001B[38;5;241m=\u001B[39m expr[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[0;32m-> 3063\u001B[0m jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mselectExpr(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jseq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexpr\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   3064\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2624\u001B[0m, in \u001B[0;36mDataFrame._jseq\u001B[0;34m(self, cols, converter)\u001B[0m\n\u001B[1;32m   2618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_jseq\u001B[39m(\n\u001B[1;32m   2619\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2620\u001B[0m     cols: Sequence,\n\u001B[1;32m   2621\u001B[0m     converter: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrimitiveType\u001B[39m\u001B[38;5;124m\"\u001B[39m, JavaObject]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2622\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JavaObject:\n\u001B[1;32m   2623\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: Column is not iterable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This does not work as selectExpr can only take column names or SQL style expressions on column names\n",
    "users_df.selectExpr(col('id'), 'first_name','last_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1cac8bc-3d00-4da1-9250-697f7d0de9ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat,lit,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75535ba6-80f1-4772-8f8a-38fe5d5b0cd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-------------------+\n| id|first_name|   last_name|          full_name|\n+---+----------+------------+-------------------+\n|  1|    Corrie|Van den Oord|Corrie,Van den Oord|\n|  2|      John|        Cena|          John,Cena|\n|  3|     James|        Bond|         James,Bond|\n|  4|    Robert|      Dowrey|      Robert,Dowrey|\n|  5|     Chris|  Hemmsworth|   Chris,Hemmsworth|\n+---+----------+------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    select(\n",
    "        'id','first_name','last_name',\n",
    "        concat(users_df['first_name'], lit(','),col('last_name')).alias('full_name')\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567b13f3-d7f1-41d5-86d9-12b5a4959858",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-------------------+\n| id|first_name|   last_name|          full_name|\n+---+----------+------------+-------------------+\n|  1|    Corrie|Van den Oord|Corrie,Van den Oord|\n|  2|      John|        Cena|          John,Cena|\n|  3|     James|        Bond|         James,Bond|\n|  4|    Robert|      Dowrey|      Robert,Dowrey|\n|  5|     Chris|  Hemmsworth|   Chris,Hemmsworth|\n+---+----------+------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_df.alias('u').selectExpr('id','first_name','last_name', \"concat(u.first_name, ',', u.last_name) as full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3a7fa8-7332-4567-9ad9-50ca87990b63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "users_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e816f5c-af5a-4940-8a2a-4c3d2346b669",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-------------------+\n| id|first_name|   last_name|          full_name|\n+---+----------+------------+-------------------+\n|  1|    Corrie|Van den Oord|Corrie,Van den Oord|\n|  2|      John|        Cena|          John,Cena|\n|  3|     James|        Bond|         James,Bond|\n|  4|    Robert|      Dowrey|      Robert,Dowrey|\n|  5|     Chris|  Hemmsworth|   Chris,Hemmsworth|\n+---+----------+------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT id,first_name,last_name,\n",
    "          concat(u.first_name, ',', u.last_name) AS full_name\n",
    "          FROM users as u\n",
    "          \n",
    " \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b0647f9-ed00-4273-bc97-10639f1754d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06 - Referring Columns using Spark Dataframe name 2023-07-15 14:34:16",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
