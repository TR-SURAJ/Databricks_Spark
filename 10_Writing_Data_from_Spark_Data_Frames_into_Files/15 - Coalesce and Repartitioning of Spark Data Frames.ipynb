{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7c44d01-1b1b-4a40-aecc-7d9f61e2a0de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- `coalesce` and `repartition` are functions on top of the dataframe. Do not get confused between **coalesce** on DataFrame and the coalsece function available to deal with null in a given col\n",
    "- `coalesce` is typically used to **reduce number of partitions** to deal with as part of downstream processing\n",
    "- `repartition` is used to reshuffle the data to **higher or lower number of partitions** to deal with as part of downstream processing\n",
    "- Make sure to use a cluster with higher configuration, if you would like to run and experience by your self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17301af8-4726-46de-9da1-75754a9b9feb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('dbfs:/databricks-datasets/asa/airlines', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902b4937-a645-46b5-bbc9-8e155f6d87c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method coalesce in module pyspark.sql.dataframe:\n\ncoalesce(numPartitions: int) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` that has exactly `numPartitions` partitions.\n    \n    Similar to coalesce defined on an :class:`RDD`, this operation results in a\n    narrow dependency, e.g. if you go from 1000 partitions to 100 partitions,\n    there will not be a shuffle, instead each of the 100 new partitions will\n    claim 10 of the current partitions. If a larger number of partitions is requested,\n    it will stay at the current number of partitions.\n    \n    However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,\n    this may result in your computation taking place on fewer nodes than\n    you like (e.g. one node in the case of numPartitions = 1). To avoid this,\n    you can call repartition(). This will add a shuffle step, but means the\n    current upstream partitions will be executed in parallel (per whatever\n    the current partitioning is).\n    \n    .. versionadded:: 1.4.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    numPartitions : int\n        specify the target number of partitions\n    \n    Returns\n    -------\n    :class:`DataFrame`\n    \n    Examples\n    --------\n    >>> df = spark.range(10)\n    >>> df.coalesce(1).rdd.getNumPartitions()\n    1\n\n"
     ]
    }
   ],
   "source": [
    "help(df.coalesce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d11297-936a-4621-9c83-f7371ed238a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method repartition in module pyspark.sql.dataframe:\n\nrepartition(numPartitions: Union[int, ForwardRef('ColumnOrName')], *cols: 'ColumnOrName') -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` partitioned by the given partitioning expressions. The\n    resulting :class:`DataFrame` is hash partitioned.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    numPartitions : int\n        can be an int to specify the target number of partitions or a Column.\n        If it is a Column, it will be used as the first partitioning column. If not specified,\n        the default number of partitions is used.\n    cols : str or :class:`Column`\n        partitioning columns.\n    \n        .. versionchanged:: 1.6.0\n           Added optional arguments to specify the partitioning columns. Also made numPartitions\n           optional if partitioning columns are specified.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        Repartitioned DataFrame.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame(\n    ...     [(14, \"Tom\"), (23, \"Alice\"), (16, \"Bob\")], [\"age\", \"name\"])\n    \n    Repartition the data into 10 partitions.\n    \n    >>> df.repartition(10).rdd.getNumPartitions()\n    10\n    \n    Repartition the data into 7 partitions by 'age' column.\n    \n    >>> df.repartition(7, \"age\").rdd.getNumPartitions()\n    7\n    \n    Repartition the data into 7 partitions by 'age' and 'name columns.\n    \n    >>> df.repartition(3, \"name\", \"age\").rdd.getNumPartitions()\n    3\n\n"
     ]
    }
   ],
   "source": [
    "help(df.repartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c1499f0-8a16-4620-b47c-8cda3bc777b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n|1988|    1|         9|        6|   1348|      1331|   1458|      1435|           PI|      942|     NA|               70|            64|     NA|      23|      17|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        10|        7|   1334|      1331|   1443|      1435|           PI|      942|     NA|               69|            64|     NA|       8|       3|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        11|        1|   1446|      1331|   1553|      1435|           PI|      942|     NA|               67|            64|     NA|      78|      75|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        12|        2|   1334|      1331|   1438|      1435|           PI|      942|     NA|               64|            64|     NA|       3|       3|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        13|        3|   1341|      1331|   1503|      1435|           PI|      942|     NA|               82|            64|     NA|      28|      10|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        14|        4|   1332|      1331|   1447|      1435|           PI|      942|     NA|               75|            64|     NA|      12|       1|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        15|        5|   1331|      1331|   1434|      1435|           PI|      942|     NA|               63|            64|     NA|      -1|       0|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        16|        6|   1327|      1331|   1427|      1435|           PI|      942|     NA|               60|            64|     NA|      -8|      -4|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        17|        7|   1331|      1331|   1440|      1435|           PI|      942|     NA|               69|            64|     NA|       5|       0|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        18|        1|   1349|      1331|   1519|      1435|           PI|      942|     NA|               90|            64|     NA|      44|      18|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        19|        2|   1337|      1331|   1438|      1435|           PI|      942|     NA|               61|            64|     NA|       3|       6|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        20|        3|   1337|      1331|   1452|      1435|           PI|      942|     NA|               75|            64|     NA|      17|       6|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        21|        4|   1330|      1331|   1459|      1435|           PI|      942|     NA|               89|            64|     NA|      24|      -1|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        22|        5|   1331|      1331|   1434|      1435|           PI|      942|     NA|               63|            64|     NA|      -1|       0|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        23|        6|   1333|      1331|   1436|      1435|           PI|      942|     NA|               63|            64|     NA|       1|       2|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        24|        7|   1328|      1331|   1430|      1435|           PI|      942|     NA|               62|            64|     NA|      -5|      -3|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        25|        1|   1330|      1331|   1444|      1435|           PI|      942|     NA|               74|            64|     NA|       9|      -1|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        26|        2|   1407|      1331|   1518|      1435|           PI|      942|     NA|               71|            64|     NA|      43|      36|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        27|        3|   1332|      1331|   1445|      1435|           PI|      942|     NA|               73|            64|     NA|      10|       1|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n|1988|    1|        28|        4|   1331|      1331|   1438|      1435|           PI|      942|     NA|               67|            64|     NA|       3|       0|   SYR| BWI|     273|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4621655a-e6ba-441c-a1c0-035f6ba1da57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- `repartition` incurs shuffling and it takes time as data has to be shuffled to newer number of partitions\n",
    "- Also you can `repartition` the DataFrame based on specified columns\n",
    "- `coalesce` does not incur shuffling\n",
    "- We use `coalesce` quite often before writing the data to fewer number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c860b826-f25a-431e-be72-10543bfb16f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('dbfs:/databricks-datasets/asa/airlines', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d218427-c30e-4d8b-bdc8-bccc7b287b0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1987.csv', name='1987.csv', size=127162942, modificationTime=1459744248000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1988.csv', name='1988.csv', size=501039472, modificationTime=1459744260000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1989.csv', name='1989.csv', size=486518821, modificationTime=1459744335000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1990.csv', name='1990.csv', size=509194687, modificationTime=1459744384000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1991.csv', name='1991.csv', size=491210093, modificationTime=1459744438000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1992.csv', name='1992.csv', size=492313731, modificationTime=1459744493000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1993.csv', name='1993.csv', size=490753652, modificationTime=1459744545000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1994.csv', name='1994.csv', size=501558665, modificationTime=1459744608000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1995.csv', name='1995.csv', size=530751568, modificationTime=1459744663000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1996.csv', name='1996.csv', size=533922363, modificationTime=1459744718000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1997.csv', name='1997.csv', size=540347861, modificationTime=1459744776000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1998.csv', name='1998.csv', size=538432875, modificationTime=1459744834000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/1999.csv', name='1999.csv', size=552926022, modificationTime=1459744896000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2000.csv', name='2000.csv', size=570151613, modificationTime=1459744954000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2001.csv', name='2001.csv', size=600411462, modificationTime=1459745016000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2002.csv', name='2002.csv', size=530507013, modificationTime=1459745079000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2003.csv', name='2003.csv', size=626745242, modificationTime=1459745141000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2004.csv', name='2004.csv', size=669879113, modificationTime=1459745218000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2005.csv', name='2005.csv', size=671027265, modificationTime=1459745287000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2006.csv', name='2006.csv', size=672068096, modificationTime=1459745364000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2007.csv', name='2007.csv', size=702878193, modificationTime=1459745438000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/airlines/2008.csv', name='2008.csv', size=689413344, modificationTime=1459745523000)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls('dbfs:/databricks-datasets/asa/airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604e1927-9b34-4069-ba31-992f2ec79806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "134c34dc-ba31-4b53-973a-2cf486b775a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coalescing the dataframe to 16\n",
    "\n",
    "df.coalesce(16).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d45e39-1b67-4c05-bd67-78466f3ad81a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not effective as coalesce can be used to reduce the number of partitions. Faster as no shuffling is involved\n",
    "df.coalesce(186).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1d5b8c-5c7a-40d8-b0b7-01760824941e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(16).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e32865db-19ab-477e-b8bc-63fd3b088262",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.repartition(186, 'Year', 'Month').rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98fc9c44-25d7-428d-a5fb-3dec0a519784",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "15 - Coalesce and Repartitioning of Spark Data Frames",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
