{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b86c4606-f3af-40df-acda-27e34c929a2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- We can write data from Sprak Data Frame into CSV files using multiple approches\n",
    "- Approach 1: df.write.csv('path_to_folder')\n",
    "- Approach 2: df.write.format('csv').save('path_to_folder')\n",
    "- The column names from the schema can be added as header to each of the files by saying header=True\n",
    "- We can also write data into files using characters other than comma as delimiters/seperators\n",
    "- We can also compress the data while writing into files using csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cfdb18f-2b39-4d1e-813d-9438bcba67cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "courses = [\n",
    "    {   \n",
    "        'course_id': 1,\n",
    "        'course_name': \"Python Bootcamp\",\n",
    "        'suitable_for': 'Beginner',\n",
    "        'enrollment': 1100093,\n",
    "        'stars': 4.6,\n",
    "        'number_of_ratings': 218066\n",
    "    },\n",
    "    {   \n",
    "        'course_id': 2,\n",
    "        'course_name': \"angular - the complete guide\",\n",
    "        'suitable_for': 'Intermediate',\n",
    "        'enrollment': 34567,\n",
    "        'stars': 4.5,\n",
    "        'number_of_ratings': 347912\n",
    "    },\n",
    "    {\n",
    "        'course_id': 3,\n",
    "        'course_name': \"Java In-Depth\",\n",
    "        'suitable_for': 'Adavanced',\n",
    "        'enrollment': 2345321,\n",
    "        'stars': 4.8,\n",
    "        'number_of_ratings': 23789\n",
    "    },\n",
    "    {\n",
    "        'course_id': 4,\n",
    "        'course_name': \"C++ Beginner guide\",\n",
    "        'suitable_for': 'Beginner',\n",
    "        'enrollment': 32145,\n",
    "        'stars': 4.2,\n",
    "        'number_of_ratings': 5678\n",
    "    },\n",
    "    {\n",
    "        'course_id': 5,\n",
    "        'course_name': \"Data Science Practical approach\",\n",
    "        'suitable_for': 'Intermediate',\n",
    "        'enrollment': 67897,\n",
    "        'stars': 4.6,\n",
    "        'number_of_ratings': 267576\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c204148b-7ef4-4f39-b17d-41a030d86fa7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259fad01-9090-4180-8591-d744bd8dd0af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_df = spark.createDataFrame([Row(**course) for course in courses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33919b65-5517-497a-8668-a5fb9b03bae6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+----------+-----+-----------------+\n|course_id|         course_name|suitable_for|enrollment|stars|number_of_ratings|\n+---------+--------------------+------------+----------+-----+-----------------+\n|        1|     Python Bootcamp|    Beginner|   1100093|  4.6|           218066|\n|        2|angular - the com...|Intermediate|     34567|  4.5|           347912|\n|        3|       Java In-Depth|   Adavanced|   2345321|  4.8|            23789|\n|        4|  C++ Beginner guide|    Beginner|     32145|  4.2|             5678|\n|        5|Data Science Prac...|Intermediate|     67897|  4.6|           267576|\n+---------+--------------------+------------+----------+-----+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "course_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5f5c380-99b2-4324-8b33-478ee453d156",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f3f681-3ed0-4838-9bb1-02300000a01d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/user/root/course/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_5449931784188502323', name='_committed_5449931784188502323', size=742, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_644016347177183303', name='_committed_644016347177183303', size=376, modificationTime=1698049135000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_5449931784188502323', name='_started_5449931784188502323', size=0, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_644016347177183303', name='_started_644016347177183303', size=0, modificationTime=1698049134000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00000-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-19-1-c000.json', name='part-00000-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-19-1-c000.json', size=134, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00001-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-20-1-c000.json', name='part-00001-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-20-1-c000.json', size=149, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00002-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-21-1-c000.json', name='part-00002-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-21-1-c000.json', size=132, modificationTime=1698049214000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00003-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-22-1-c000.json', name='part-00003-tid-5449931784188502323-fa6ae0b9-bd7f-4e87-8a5d-b947ae87580a-22-1-c000.json', size=285, modificationTime=1698049214000)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a990522-f7c5-4fe0-bf93-debac6b6eafd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.rm(f'/user/{username}/course', recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e2c8f4-dfe5-483a-bc30-be55166b15de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-22963888070541>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mls\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/user/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43musername\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/course\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
       "\n",
       "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o886.ls.\n",
       ": java.io.FileNotFoundException: No such file or directory /user/root/course\n",
       "\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$2(DatabricksFileSystemV2.scala:138)\n",
       "\tat com.databricks.s3a.S3AExceptionUtils$.convertAWSExceptionToJavaIOException(DatabricksStreamUtils.scala:66)\n",
       "\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$1(DatabricksFileSystemV2.scala:118)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:666)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:684)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:639)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:639)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:661)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperationWithResultTags(DatabricksFileSystemV2.scala:639)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperation(DatabricksFileSystemV2.scala:639)\n",
       "\tat com.databricks.backend.daemon.data.client.DBFSV2.listStatus(DatabricksFileSystemV2.scala:118)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:254)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$2(DBUtilsCore.scala:223)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:145)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$1(DBUtilsCore.scala:221)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:140)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:221)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:211)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:666)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:684)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:661)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:133)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:211)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-22963888070541>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mls\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/user/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43musername\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/course\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n\n\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o886.ls.\n: java.io.FileNotFoundException: No such file or directory /user/root/course\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$2(DatabricksFileSystemV2.scala:138)\n\tat com.databricks.s3a.S3AExceptionUtils$.convertAWSExceptionToJavaIOException(DatabricksStreamUtils.scala:66)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.$anonfun$listStatus$1(DatabricksFileSystemV2.scala:118)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:666)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:684)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:639)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:639)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:661)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperationWithResultTags(DatabricksFileSystemV2.scala:639)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperation(DatabricksFileSystemV2.scala:639)\n\tat com.databricks.backend.daemon.data.client.DBFSV2.listStatus(DatabricksFileSystemV2.scala:118)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:254)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$2(DBUtilsCore.scala:223)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:145)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$1(DBUtilsCore.scala:221)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:140)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:221)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:211)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:666)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:684)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:661)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:69)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:133)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:211)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "java.io.FileNotFoundException: No such file or directory /user/root/course",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf4e4e-3fce-40af-b8bd-6998e3ec97ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Default behavior. It will delimit the data using comma as seperator\n",
    "course_df.write.csv(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b84c319-0067-4096-9fdc-3f282fafca0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/user/root/course/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_154650268415425654', name='_committed_154650268415425654', size=372, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_154650268415425654', name='_started_154650268415425654', size=0, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00000-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-27-1-c000.csv', name='part-00000-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-27-1-c000.csv', size=46, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00001-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-28-1-c000.csv', name='part-00001-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-28-1-c000.csv', size=61, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00002-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-29-1-c000.csv', name='part-00002-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-29-1-c000.csv', size=44, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00003-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-30-1-c000.csv', name='part-00003-tid-154650268415425654-86b59274-d5ab-4d72-ad7e-6b5599faeb8f-30-1-c000.csv', size=109, modificationTime=1698050142000)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca15175d-f0dc-4285-9824-2a0f5d7275c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_df.write.format('csv').save(f'/user/{username}/course',mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "790c607b-1f36-4e99-bdea-4744dfbc5c0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/user/root/course/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_154650268415425654', name='_committed_154650268415425654', size=372, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_4292193513688800745', name='_committed_4292193513688800745', size=734, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_154650268415425654', name='_started_154650268415425654', size=0, modificationTime=1698050142000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_4292193513688800745', name='_started_4292193513688800745', size=0, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00000-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-31-1-c000.csv', name='part-00000-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-31-1-c000.csv', size=46, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00001-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-32-1-c000.csv', name='part-00001-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-32-1-c000.csv', size=61, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00002-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-33-1-c000.csv', name='part-00002-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-33-1-c000.csv', size=44, modificationTime=1698050371000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00003-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-34-1-c000.csv', name='part-00003-tid-4292193513688800745-fdc7a98b-2de7-4bc5-98cf-8de0498c3931-34-1-c000.csv', size=109, modificationTime=1698050371000)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c767c4-b008-4af8-ba84-42e097dcf6b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+\n|value                                                          |\n+---------------------------------------------------------------+\n|4,C++ Beginner guide,Beginner,32145,4.2,5678                   |\n|5,Data Science Practical approach,Intermediate,67897,4.6,267576|\n|2,angular - the complete guide,Intermediate,34567,4.5,347912   |\n|1,Python Bootcamp,Beginner,1100093,4.6,218066                  |\n|3,Java In-Depth,Adavanced,2345321,4.8,23789                    |\n+---------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using spark.read.text we can read the raw data as single column dataframe\n",
    "# We can confirm default delimiter as comma by looking at the data\n",
    "spark.read.text(f'/user/{username}/course').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b93e4115-4533-4f8e-9beb-cab837e70c29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05 - Writing Spark Data Frames into CSV files",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
