{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc85e70-b22c-4295-a332-da9ced3e2ee0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "courses = [\n",
    "    {   \n",
    "        'course_id': 1,\n",
    "        'course_name': \"Python Bootcamp\",\n",
    "        'suitable_for': 'Beginner',\n",
    "        'enrollment': 1100093,\n",
    "        'stars': 4.6,\n",
    "        'number_of_ratings': 218066\n",
    "    },\n",
    "    {   \n",
    "        'course_id': 2,\n",
    "        'course_name': \"angular - the complete guide\",\n",
    "        'suitable_for': 'Intermediate',\n",
    "        'enrollment': 34567,\n",
    "        'stars': 4.5,\n",
    "        'number_of_ratings': 347912\n",
    "    },\n",
    "    {\n",
    "        'course_id': 3,\n",
    "        'course_name': \"Java In-Depth\",\n",
    "        'suitable_for': 'Adavanced',\n",
    "        'enrollment': 2345321,\n",
    "        'stars': 4.8,\n",
    "        'number_of_ratings': 23789\n",
    "    },\n",
    "    {\n",
    "        'course_id': 4,\n",
    "        'course_name': \"C++ Beginner guide\",\n",
    "        'suitable_for': 'Beginner',\n",
    "        'enrollment': 32145,\n",
    "        'stars': 4.2,\n",
    "        'number_of_ratings': 5678\n",
    "    },\n",
    "    {\n",
    "        'course_id': 5,\n",
    "        'course_name': \"Data Science Practical approach\",\n",
    "        'suitable_for': 'Intermediate',\n",
    "        'enrollment': 67897,\n",
    "        'stars': 4.6,\n",
    "        'number_of_ratings': 267576\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51394cb8-e997-4984-b089-9e03b7c2c97b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1df339ea-97b7-435d-9ffe-3eb73614a834",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_df = spark.createDataFrame([Row(**course) for course in courses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275080ac-772d-409f-951c-d9d03f82417d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df83f22a-98a9-473e-916a-15177ef19b16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.rm(f'/user/{username}/course',recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a828092-3afb-457c-bd86-d1bdd1cc6a7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method json in module pyspark.sql.readwriter:\n\njson(path: str, mode: Optional[str] = None, compression: Optional[str] = None, dateFormat: Optional[str] = None, timestampFormat: Optional[str] = None, lineSep: Optional[str] = None, encoding: Optional[str] = None, ignoreNullFields: Union[bool, str, NoneType] = None) -> None method of pyspark.sql.readwriter.DataFrameWriter instance\n    Saves the content of the :class:`DataFrame` in JSON format\n    (`JSON Lines text format or newline-delimited JSON <http://jsonlines.org/>`_) at the\n    specified path.\n    \n    .. versionadded:: 1.4.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    path : str\n        the path in any Hadoop supported file system\n    mode : str, optional\n        specifies the behavior of the save operation when data already exists.\n    \n        * ``append``: Append contents of this :class:`DataFrame` to existing data.\n        * ``overwrite``: Overwrite existing data.\n        * ``ignore``: Silently ignore this operation if data already exists.\n        * ``error`` or ``errorifexists`` (default case): Throw an exception if data already                 exists.\n    \n    Other Parameters\n    ----------------\n    Extra options\n        For the extra options, refer to\n        `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option>`_\n        for the version you use.\n    \n        .. # noqa\n    \n    Examples\n    --------\n    Write a DataFrame into a JSON file and read it back.\n    \n    >>> import tempfile\n    >>> with tempfile.TemporaryDirectory() as d:\n    ...     # Write a DataFrame into a JSON file\n    ...     spark.createDataFrame(\n    ...         [{\"age\": 100, \"name\": \"Hyukjin Kwon\"}]\n    ...     ).write.json(d, mode=\"overwrite\")\n    ...\n    ...     # Read the JSON file as a DataFrame.\n    ...     spark.read.format(\"json\").load(d).show()\n    +---+------------+\n    |age|        name|\n    +---+------------+\n    |100|Hyukjin Kwon|\n    +---+------------+\n\n"
     ]
    }
   ],
   "source": [
    "help(course_df.write.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e8491b-382f-4404-b782-c166332cf409",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_df.\\\n",
    "    coalesce(1).\\\n",
    "    write.\\\n",
    "    json(\n",
    "        f'/user/{username}/course',\n",
    "        mode='overwrite'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5763b2a6-d8c2-45a4-8671-e4c11450f6cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/user/root/course/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1698120253000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_3369753614984232727', name='_committed_3369753614984232727', size=112, modificationTime=1698120253000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_3369753614984232727', name='_started_3369753614984232727', size=0, modificationTime=1698120250000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00000-tid-3369753614984232727-bf67c037-e42e-4e22-a0c1-ac18fd4de7b3-0-1-c000.json', name='part-00000-tid-3369753614984232727-bf67c037-e42e-4e22-a0c1-ac18fd4de7b3-0-1-c000.json', size=700, modificationTime=1698120252000)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1250f5-7f63-4fab-acbb-273c60a3697a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_df.\\\n",
    "    coalesce(1).\\\n",
    "    write.\\\n",
    "    format('json').\\\n",
    "    save(\n",
    "        f'/user/{username}/course',\n",
    "        mode='overwrite'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b00e614e-f038-4a7b-ae9e-6e3f6e3bb539",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/user/root/course/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1698120470000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_3369753614984232727', name='_committed_3369753614984232727', size=112, modificationTime=1698120253000),\n",
       " FileInfo(path='dbfs:/user/root/course/_committed_8412628378454775660', name='_committed_8412628378454775660', size=210, modificationTime=1698120469000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_3369753614984232727', name='_started_3369753614984232727', size=0, modificationTime=1698120250000),\n",
       " FileInfo(path='dbfs:/user/root/course/_started_8412628378454775660', name='_started_8412628378454775660', size=0, modificationTime=1698120469000),\n",
       " FileInfo(path='dbfs:/user/root/course/part-00000-tid-8412628378454775660-c0ec4d87-da88-4313-be17-943221ffd89e-1-1-c000.json', name='part-00000-tid-8412628378454775660-c0ec4d87-da88-4313-be17-943221ffd89e-1-1-c000.json', size=700, modificationTime=1698120469000)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(f'/user/{username}/course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc5bde26-db4d-4390-bb7f-99f7ff016cec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+-----------------+-----+------------+\n|course_id|         course_name|enrollment|number_of_ratings|stars|suitable_for|\n+---------+--------------------+----------+-----------------+-----+------------+\n|        1|     Python Bootcamp|   1100093|           218066|  4.6|    Beginner|\n|        2|angular - the com...|     34567|           347912|  4.5|Intermediate|\n|        3|       Java In-Depth|   2345321|            23789|  4.8|   Adavanced|\n|        4|  C++ Beginner guide|     32145|             5678|  4.2|    Beginner|\n|        5|Data Science Prac...|     67897|           267576|  4.6|Intermediate|\n+---------+--------------------+----------+-----------------+-----+------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.json(f'/user/{username}/course').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aa9d189-2bf0-425a-aa0d-f273304dc149",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10 - Writing Spark Data Frames into JSON Files",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
